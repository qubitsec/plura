# 필상 시스템 — Day 71 레이크하우스(Lakehouse) 표준: Iceberg/Parquet · CDC/ETL · RLS/주권 · 비용 가드

1. **날짜**

* 2024-11-19

2. **목표**

* **콜드/아카이브 로그·증거 요약**을 **Lakehouse(Iceberg/Parquet)**로 일원화하여
  **대규모 분석·리플레이·리포트**를 저비용으로 수행
* **스키마 진화(EMC)·주권(RLS)·비용 가드**를 내장해 **p95 쿼리 ≤ 20s**, **월 TCO 25%↓** 달성

---

3. **내용**

### A. 아키텍처(개요)

```
Object Storage(S3/MinIO, 리전별)
   └─ lake/{region}/{domain}/{table}  # Iceberg 테이블
ETL/CDC: Kafka Connect + Spark(또는 Flink) + dbt-iceberg
Query: Trino/Presto + Spark SQL (Read-Only)
Governance: Glue/Unity Catalog(카탈로그), OPA(RLS), FinOps 가드
```

* **리전 분리**: `kr`/`jp` 카탈로그 독립(교차 쿼리 금지).
* **테이블 권장**: `logs_raw_lake`, `events_detect_lake`, `incidents_lake`, `evidence_index_lake`(원본 링크/해시만).

### B. 포맷/테이블 표준

* **파일**: Parquet v2, **row group 128MB**, **ZSTD** 압축(레벨 6)
* **테이블**: **Iceberg v2**(숨김 파티션/Position delete/Equality delete 지원)
* **파티션**: `region` → `tenant_bucket(hash64)` → `date=YYYY-MM-DD` → 선택적으로 `dst_host_bucket`
* **정렬 힌트**: `sort_order = (date, tenant_bucket, ts_epoch)`로 스캔 최소화

### C. 적재 경로(ETL/CDC)

* **Batch**: Solr 컬렉션 롤오버 시점 스냅샷 → Parquet 변환 → Iceberg **MERGE INTO**
* **CDC**: Kafka `*.retry/processed` 토픽 → 미도달/수정분 **Upsert**
* **스크리너**: PII 검사(정규식/테이블 정책) 통과 시에만 쓰기 허용
* **메타 기록**: `load_id, source, rows, bytes, checksum, dp_epsilon?`를 `loads_audit`에 저장(해시체인)

### D. 스키마 진화(EMC) & 품질

* **Expand**: 새 컬럼 **nullable + default**로 추가(메타에 버전 기록)
* **Migrate**: 백필 잡(시간/테넌트 윈도우), 품질 지표(`null_rate`, `type_error`) 트래킹
* **Contract**: 2주 관찰 후 소비자 전환 확인 → 구 컬럼 Soft-deprecate → 차기 리비전에서 삭제
* **검증**: dbt 테스트(무결성/참조), **Nightly Reconcile**(행수/집계값 비교)

### E. 보안·주권·RLS

* **카탈로그 정책(OPA)**

  * `deny if query.region != token.region`
  * `tenant_id == token.tenant` 필터 강제(RLS)
* **보기(View)**: `*_view`는 항상 `SELECT ... WHERE tenant_id = session.tenant`
* **증거(EPKG)**: **원본 Key/ETag**만 저장, 원문 데이터는 **링크+서명 URL**로 접근(기본 금지)

### F. 비용·성능 가드

* **파일 크기 정규화**: 64–512MB 사이 유지(작은 파일은 **Compaction**), 주간 **OPTIMIZE**
* **메타데이터 Pruning**: Iceberg **hidden partition** + **TTL 인덱스**
* **쿼리 제한**: `max_scan_bytes`, `max_execution_time(120s)`, `max_rows(5e7)`
* **캐시**: Trino **Alluxio/SSD 캐시** 옵션, 인기 테이블 **Result Cache 5–15m**
* **FinOps 알람**: 스캔 바이트 p95↑, 쿼리 실패/타임아웃↑ → 티켓 자동 생성

### G. 공통 스키마(발췌)

```sql
CREATE TABLE incidents_lake (
  region string, tenant_id string, date date,
  incident_id string, rule_id string, severity string, state string,
  dst_host string, ip_bucket string, ts timestamp,
  ti_score int, evidence_uri array<string>,
  _load_id string, _ingested_at timestamp
)
PARTITIONED BY (region, tenant_bucket, date);
```

> 원칙: **원 IP/원문 파라미터 금지**, `ip_bucket`·`param_sig/uri_sig`만 저장(Privacy Day 57 정합).

### H. 표준 쿼리(Trino/Presto)

1. **24h 규칙 영향도**

```sql
SELECT rule_id, severity, COUNT(*) cnt
FROM incidents_lake
WHERE region='kr' AND tenant_id='TEN_kr_x' AND date BETWEEN DATE '2024-11-18' AND DATE '2024-11-19'
GROUP BY 1,2 ORDER BY cnt DESC LIMIT 20;
```

2. **FP 의심 비중(혼재)**

```sql
SELECT dst_host, SUM(CASE WHEN status=406 AND blocked=1 THEN 1 ELSE 0 END) AS blocked,
       SUM(CASE WHEN status=200 THEN 1 ELSE 0 END) AS ok
FROM logs_raw_lake
WHERE region='kr' AND tenant_id='TEN_kr_x' AND date = DATE '2024-11-19'
GROUP BY 1 HAVING blocked>0 AND ok>0 ORDER BY blocked DESC;
```

3. **TI 고위험 상위 ASN**

```sql
SELECT asn, COUNT(*) AS hits
FROM events_detect_lake
WHERE region='kr' AND ti_score>=80 AND date>=DATE '2024-11-12'
GROUP BY 1 ORDER BY hits DESC LIMIT 10;
```

### I. 운영/데이터 품질 대시

* 지표: `scan_bytes`, `compaction_tasks`, `small_file_ratio`, `query_p95`, `cost_per_tb`, `pii_violation=0`, `rls_denies`
* **SLO**: 쿼리 p95 **≤ 20s**, `small_file_ratio < 15%`, PII 위반 **0**, 교차 리전 쿼리 **0**

### J. API/자동화(발췌)

* `POST /v1/lake/load { table, range, mode:"batch|cdc" }`
* `POST /v1/lake/optimize { table, strategy:"binpack|zorder", max_tasks }`
* `GET  /v1/lake/metrics?table=incidents_lake&range=24h`
* `POST /v1/lake/policy/test { query, token }` — RLS/주권 사전 검증

---

4. **예시 설명 (월간 리포트 — 18s 내 완결, 비용 32%↓)**

1) 월말 `incidents_lake`에서 엔터프라이즈 테넌트 **Top-규칙/호스트/ASN** 리포트 생성(Trino, 14–18s).
2) Compaction + Z-Order(`date, tenant_bucket, ts`) 후 스캔 바이트 **−41%**, 쿼리 p95 **−36%**.
3) 교차 리전/PII 위반 **0**, 비용(TB-scanned 기준) **−32%**. 리포트는 `reports/{region}`에 서명 저장.
   → 결과: **Iceberg/Parquet + RLS/가드레일**로 대규모 분석을 **저비용·고신뢰**로 표준화하고, 운영·리포트/리플레이 품질을 안정적으로 향상.
