# 왜 기존 전문가들이 프루라를 몰랐나?

1. **시장 습관**

* 늘 쓰던 제품만 봤다 → 새로운 방식(“로그를 먼저 만들기”)은 관심 밖.

2. **평가 방식의 한계**

* “알람 몇 개 잡나?”만 본다 → **증거가 얼마나 잘 남는가**는 안 본다.
* 테스트 때 **웹 본문(POST/응답)**을 빼고 시험하는 경우가 많다.

3. **기술 관점이 달랐다**

* 보통은 “있는 로그를 모아 분석”.
* 프루라는 **로그를 직접 만들고 → AI가 바로 분석 → 자동 대응/증거화**.
* 처음엔 낯설다.

4. **레퍼런스/인증 이슈**

* 보안 특성상 사례 공개가 어렵다.
* 기존 분류(WAF/EDR/SIEM)에 **딱 들어맞지 않는** 새 범주라 더 낯설다.

5. **설명 난이도**

* “로그가 없으면 탐지도 없다”는 말을 **그림/시나리오로** 안 보여주면 어렵게 느껴진다.

---

# 바로 할 수 있는 해결책 (실무 체크리스트)

1. **짧은 체험 데모**

* 한 장면: *웹 본문 공격 → 계정 시도 → 호스트 흔적*
* 결과: **패킷 → 로그 → AI 판단 → 자동 차단 → 보고서**까지 한 눈에.

2. **평가표를 바꾸자**

* 알람 개수 + **증거성(다시 재현 가능?)** + **가시성(본문/감사로그 보이냐?)** + **속도(TTD/TTR)** + **운영비 절감**을 함께 점수화.

3. **원클릭 가이드 제공**

* 미러링/SPAN, OS 감사정책을 **30분 내 켜고 끌 수 있는** 스크립트 제공(원복 포함).

4. **작은 공개 사례 3종**

* (a) 본문 기반 제로데이 차단
* (b) 계정 탈취 실시간 차단
* (c) 자동 포렌식 리포트
  → 개인정보는 가리고 **그림/스크린샷**으로 공유.

5. **기존 솔루션과 연동**

* “대체”가 아니라 **“증강”**. Splunk/ELK/QRadar로 **함께** 보이게 연결.

6. **정책 한 페이지**

* 메시지 한 줄: **“정부 실태조사에 ‘로그 생성’ 항목을 넣어야 진짜 보안이 시작된다.”**
* 간단 그래픽 + 지표 예시 포함.

---

## 한 줄 요약

프루라는 **“로그를 먼저 만들고, AI로 바로 대응하는”** 새 방식이라
**예전 방식의 평가**로는 잘 보이지 않았습니다.
**체험 데모 + 바뀐 평가표 + 작은 공개 사례**면 인식이 빠르게 바뀝니다.
